---
title       : Introduction à la classification (4)
subtitle    : Description de la partition
author      : Elisabeth Morand-Bénédicte Garnier
job         : SMS

framework   : io2012      # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}

hitheme     : zenburn 


widgets     : [bootstrap, shiny, interactive,mathjax,quiz]           # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
ext_widgets: {rCharts: [libraries/nvd3]}
---

##  Choix de la partition

1. Indice fondé sur la somme des carrés
2. Critère de Calinski
3. Graphique silhouette

---

## Somme des carrés

Indice valable pour les classifications ascendantes hierarchiques. 
On souhaite savoir si le saut de s à s-1 classes est "important ou pas"



-  R-Square (RSQ)
-  semi partial RSQ (SPRSQ)
-  Root Mean Square Standard deviation (RMSSTD)
-  cubic clustering criterion (CCC)
-  le pseudo F
-  le pseudo $T^2$

---


## Critère de Calinski


$CH(q) = \frac{trace(B_q )/(q − 1)}{trace(W_q )/(n − q)}$


-  $Wq = \sum_k=1q \sum_{ i \in C_k}(x_i-g_k)^T$ Variance intra classe pour un partitionnement en q classes

- $Bq = \sum_{k=1}^q n_k ∗(g_k − g) (g_k − g)^T$  Variance inter classe pour un partitionnement en q classes

- $x_i$ : vecteur du $i^e$ point de la classe k 
- $g_k$ = centre de gravité de la classe $C_k$
- g =  cente de gravité total
- $n_k$ = nombre d'éléments de la classe $C_k$

---


## Graphique silhouette

>- silhouette

Soit $x_i$ un des éléments à classer, soit C la classe à laquelle l'individu appartient :

- $a(x_i)$ est la dissimilarité moyenne entre $x_i$ et les autres éléments de sa classe. 

$$a(x_i)=\frac{1}{Card(C)-1} \sum_{\underset{i \neq j}{x_j \in C}}d(x_i,x_j)$$

-  $D(x_i,A)$ la dissimilarité moyenne entre $x_i$ et les élements  de la classe A.
$$D(x_i,A)=\frac{1}{Card(A)} \sum_{x_j \in A }d(x_i,x_j)$$

- B est la classe la plus voisine de C. C'est à dire B est la classe telle que

$$D(x_i,A)=b(x_i)=\underset{A \neq C}{min}\{D(x_i,A)\}$$

---

## Graphique silhouette II

```{r disteuclid1 ,echo=FALSE, results='asis', warning=FALSE,error=FALSE}

tabtp <- read.delim("donnees/aveclesmains.txt", dec=",")
rownames(tabtp)<-tabtp[,1]
euclidienne<-dist(tabtp[,c("Longueur","Largeur","Poids")])
quantitatives<-tabtp[,c("Longueur","Largeur","Poids")]
print(xtable(as.data.frame(as.matrix(round(euclidienne,2)))),type="html")
```

On prend l'une des partitions obtenues par le critère du saut minimal: celle en 3 classes 

---

## Graphique silhouette III
```{r dcluster ,echo=FALSE, results='asis', warning=FALSE,error=FALSE, out.width=".5\\linewidth"}

library(cluster)
dd<-as.hclust(agnes(euclidienne,method="single"))
top<-data.frame(quantitatives,cutree(dd,3))
colnames(top)[4]<-"partition"
print(xtable(top),type="html")

```


**Application numérique**

Ainsi pour l'individu A :

   - a(A)=1.486607
   - D(A,{C,D})=3.415259 et D(A,{E,F})=6.23
   - La classe la plus voisine de A après sa classe d'appartenance est {C,D}

---

## Qualité du classement

- **Largeur de la silhouette**

$$s(x_i)=\frac{b(x_i)-a(x_i)}{max{a(x_i);b(x_i)}}$$

$s(x_i)$ est compris en -1 et 1.


    - $s(x_i)$ proche de 1 : 
       $x_i$ est bien classé dans C
    - $s(x_i)$ proche de 0  : 
       $x_i$ est entre C, sa classe d'appartenance, et B la classe la plus proche de $x_i$
     - $s(x_i)$ proche de -1  : 
     $x_i$ est mal classé, plus proche de B que de C, sa classe d'appartenance.



Dans le cas de notre exemple le point A est pluôt bien classé s(A)=0.564716

---

## Indices de qualité et nombre de classes

- ** Qualité d'une partition **
Moyenne des silhouettes :
$Q(k)=\frac{1}{n}\sum_{r=1}^k  n_r \bar{s_r}$


--- 

## Graphique 

```{r silhouettegraph, ,echo=FALSE, results='asis', warning=FALSE,error=FALSE, out.width=".5\\linewidth"}

#on récupère une partition et on calcule sa qualité
  dd<-agnes(euclidienne,method="single")
total<-NULL
for (i in 2:5)
{

part<-cutree(dd,i)
result<-summary(silhouette(part,euclidienne,FUN=MEAN))
Q<-sum(result$clus.avg.widths*result$clus.sizes)/sum(result$clus.sizes)
total<-rbind(total,c(i,Q))
}
plot(total,type="l",xlim=c(1,5),axes=FALSE,xlab="Nombre de classes",ylab="indice de qualite")
axis(1)
axis(2)
box()

```
On retient le nombre de classes pour lequel l'indice de qualité est le meilleur

---


## Choix du nombre de classes

Il existe une multitude d'indicateurs, ainsi dans R un package en relève 30 et vous propose de les comparer.


```{r nbclust,echo=FALSE,eval=FALSE,message=FALSE,warning=FALSE,out.width=".5\\linewidth"}
library(NbClust)
set.seed(665544)
x<-cbind(c(runif(40, 0, 1.5),rnorm(1000, 8,sd=3), runif(40, 18, 20),runif(40,17,18.5)),
         c(runif(40, 0, 1.5),rnorm(1000, 8, sd=1.5), runif(40, 0, 2),runif(40,17,18.5)))
plot(x,xlim=c(-1,21),ylim=c(0,21),asp=1, main="A classer",xlab="x",ylab="y")


NbClust(x, diss="NULL", distance = "euclidean", min.nc=2, max.nc=6, 
        method = "ward")$Best.nc

NbClust(x, diss="NULL", distance = "euclidean", min.nc=2, max.nc=6, 
        method = "single")$Best.nc
```

---




## Description d'une classe

Principe (très simple) : Comparaison de moyenne ou proportion de variables à l’intérieur des classes, avec les valeurs générales sur l’ensemble des classes. 
Une valeur test peut ensuite être calculée pour désigner les variables les plus caractéristiques (Morineau)



- Variable continue :  tk=(xmoy(k)-xmoy)/xs(k) pour une variable X
      Plus  la valeur est forte ($ \leq 1,96 $ ) ,  plus  la var est caractéristique de la classe
    
---

## Variable nominale

On compare la modalité j dans la classe $X_k$ et dans l’ensemble de la population.

Soit nkj/nk = nj/n en cas d’indépendance,  avec 

    - nk :  nb d’individus de la classe k , 
    - nj  :nombre d’individus possedant la modalite j dans la population,
    - njk : nombre d’individus possedant la modalite j dans la classe.
    
On calcule la proba P($N \geq nkj$ ). Si faible, peu de chances d’avoir un tirage au hasard.


Equivalent : Mesurer l’écart entre la proportion dans la classe et dans la population en termes d’écart types. 
Valeur test : tk(N)=N-E(N)/sk(N), avec $E(N)=n_k \times n_j/n, et sk(n)^2=n_k*((n-n_k)/(n-1))*(n_j/n)*(1-(n_j/n))$
Valeur test supérieure à 1,96 :  Modalité caractéristique ds la classe / ensemble de la population


---



